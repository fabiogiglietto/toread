name: Update Academic Feed

on:
  schedule:
    - cron: '*/30 * * * *'  # Every 30 minutes (reduces queue buildup)
  workflow_dispatch:  # Manual trigger
  push:
    branches: [ main ]
    paths:
      - 'data/**'
      - 'config.yml'
      - 'src/**'

jobs:
  update-feed:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Required for committing changes

    # Prevent concurrent runs to avoid merge conflicts
    concurrency:
      group: update-feed
      cancel-in-progress: false  # Let current run finish
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Fetch full history for proper git operations
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
    
    - name: Create directories
      run: |
        mkdir -p data output logs cache

    # Note: Cache is tracked in git, no need for actions/cache which can overwrite
    # the git-tracked cache with stale data

    - name: Download Paperpile export
      run: |
        # Download fresh BibTeX export from Paperpile
        if [ -z "${{ secrets.PAPERPILE_EXPORT_URL }}" ]; then
          echo "Error: PAPERPILE_EXPORT_URL secret is not configured"
          echo "Please add your Paperpile export URL as a GitHub secret"
          exit 1
        fi

        echo "Downloading BibTeX export from Paperpile..."
        curl -L -H "Cache-Control: no-cache" -H "Pragma: no-cache" "${{ secrets.PAPERPILE_EXPORT_URL }}" -o /tmp/paperpile_export_new.bib

        if [ ! -f "/tmp/paperpile_export_new.bib" ] || [ ! -s "/tmp/paperpile_export_new.bib" ]; then
          echo "Error: Failed to download BibTeX file or file is empty"
          exit 1
        fi

        echo "Successfully downloaded BibTeX file ($(wc -l < /tmp/paperpile_export_new.bib) lines)"

    - name: Check if Paperpile export changed
      id: bib-check
      run: |
        # Compare with previous version
        if [ -f "data/paperpile_export.bib" ]; then
          if diff -q data/paperpile_export.bib /tmp/paperpile_export_new.bib > /dev/null 2>&1; then
            echo "üìã No changes detected in Paperpile export"
            echo "changed=false" >> $GITHUB_OUTPUT
            rm /tmp/paperpile_export_new.bib
            exit 0
          else
            echo "üìã Paperpile export has changed - showing diff summary:"
            diff --brief data/paperpile_export.bib /tmp/paperpile_export_new.bib || true

            # Count entries in both files
            old_count=$(grep -c "^@" data/paperpile_export.bib 2>/dev/null || echo "0")
            new_count=$(grep -c "^@" /tmp/paperpile_export_new.bib 2>/dev/null || echo "0")
            echo "Entries: $old_count ‚Üí $new_count ($(($new_count - $old_count)))"
          fi
        else
          echo "üìã First time download - no previous export to compare"
          new_count=$(grep -c "^@" /tmp/paperpile_export_new.bib 2>/dev/null || echo "0")
          echo "Entries: $new_count"
        fi

        # Move new file into place
        mv /tmp/paperpile_export_new.bib data/paperpile_export.bib
        echo "changed=true" >> $GITHUB_OUTPUT
    
    - name: Update config with API key
      if: env.SEMANTIC_SCHOLAR_API_KEY != ''
      env:
        SEMANTIC_SCHOLAR_API_KEY: ${{ secrets.SEMANTIC_SCHOLAR_API_KEY }}
      run: |
        python -c "
        import yaml
        with open('config.yml', 'r') as f:
            config = yaml.safe_load(f)
        config['api']['semantic_scholar']['api_key'] = '${{ secrets.SEMANTIC_SCHOLAR_API_KEY }}'
        with open('config.yml', 'w') as f:
            yaml.dump(config, f, default_flow_style=False)
        "
    
    - name: Generate feeds (fast mode for scheduled runs)
      if: github.event_name == 'schedule' && steps.bib-check.outputs.changed == 'true'
      run: |
        echo "Running in fast mode for scheduled execution..."
        for i in {1..3}; do
          python -m src.main data/paperpile_export.bib -o output/ \
            --feed-title "To Read - Research Papers" \
            --feed-description "Academic papers from Paperpile enriched with metadata" \
            --rate-limit 3.0 --timeout 20 --skip-cached-enrichment && break
          echo "Attempt $i failed, retrying in 30s..."
          sleep 30
        done
    
    - name: Generate feeds (full enrichment)
      if: github.event_name != 'schedule' && steps.bib-check.outputs.changed == 'true'
      run: |
        echo "Running full enrichment for manual/push triggers..."
        for i in {1..3}; do
          python -m src.main data/paperpile_export.bib -o output/ \
            --feed-title "To Read - Research Papers" \
            --feed-description "Academic papers from Paperpile enriched with metadata" \
            --rate-limit 2.0 --timeout 30 && break
          echo "Attempt $i failed, retrying in 60s..."
          sleep 60
        done

    - name: Skip feed generation (no changes)
      if: steps.bib-check.outputs.changed != 'true'
      run: |
        echo "‚è≠Ô∏è  Skipping feed generation - no changes in Paperpile export"
        echo "This saves execution time and API quota!"
    
    - name: Check for changes
      id: git-check
      run: |
        # Ensure output directory exists and add generated files
        mkdir -p output cache
        git add data/paperpile_export.bib 2>/dev/null || true
        git add output/feed.json output/feed.xml 2>/dev/null || true
        git add cache/ 2>/dev/null || true

        # Check if there are any staged changes
        if git diff --staged --quiet; then
          echo "üìã No changes detected in feeds or BibTeX export"
          echo "changes=false" >> $GITHUB_OUTPUT
        else
          echo "üìã Changes detected - files to commit:"
          git diff --staged --name-only
          echo "changes=true" >> $GITHUB_OUTPUT
        fi

        # Also check for any unstaged changes that might cause issues
        if ! git diff-index --quiet HEAD --; then
          echo "‚ö†Ô∏è  Warning: Unstaged changes detected"
          git status --short
        fi
    
    - name: Commit and push changes
      if: steps.git-check.outputs.changes == 'true'
      shell: bash
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"

        # Prepare commit message once
        COMMIT_MSG="ü§ñ Update academic feeds - $(date -u '+%Y-%m-%d %H:%M:%S UTC')"

        # Push with retry logic - sync before each attempt
        for i in {1..5}; do
          echo "Push attempt $i of 5..."

          # Sync with remote before each attempt
          git fetch origin main
          git reset --soft origin/main
          git add data/paperpile_export.bib output/feed.json output/feed.xml cache/ 2>/dev/null || true

          # Check if there are actually changes to commit
          if git diff --staged --quiet; then
            echo "No changes after syncing with remote - already up to date"
            exit 0
          fi

          # Commit
          git commit -m "$COMMIT_MSG" || {
            echo "Failed to create commit"
            exit 1
          }

          # Try to push
          if git push origin main; then
            echo "‚úÖ Successfully pushed changes"
            exit 0
          fi

          echo "‚ùå Push failed (attempt $i), likely due to concurrent update"

          # If we're on the last attempt, exit gracefully
          if [ $i -eq 5 ]; then
            echo "üö® All push attempts failed after 5 tries"
            echo "This is expected when another workflow pushed first"
            echo "The next scheduled run will pick up any new changes"
            exit 0  # Exit gracefully - concurrency control will prevent issues
          fi

          # Wait with exponential backoff before retrying
          wait_time=$((5 * i))
          echo "Waiting ${wait_time}s before retry..."
          sleep $wait_time
        done
    
    - name: Upload feeds as artifacts
      uses: actions/upload-artifact@v4
      with:
        name: academic-feeds
        path: output/
        retention-days: 30