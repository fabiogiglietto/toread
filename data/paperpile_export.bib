@TECHREPORT{Unknown2025-qj,
  title       = "Red-Teaming in the Public Interest",
  institution = "Data \& Society",
  abstract    = "This report offers a vision for red-teaming in the public
                 interest: a process that goes beyond system-centric testing of
                 already built systems to consider the full range of ways the
                 public can be involved in evaluating genAI harms.",
  year        =  2025,
  language    = "en"
}

@ARTICLE{Ulloa2024-jm,
  title         = "Beyond time delays: How web scraping distorts measures of
                   online news consumption",
  author        = "Ulloa, Roberto and Mangold, Frank and Schmidt, Felix and
                   Gilsbach, Judith and Stier, Sebastian",
  journal       = "arXiv",
  abstract      = "As the exploration of digital behavioral data revolutionizes
                   communication research, understanding the nuances of data
                   collection methodologies becomes increasingly pertinent. This
                   study focuses on one prominent data collection approach, web
                   scraping, and more specifically, its application in the
                   growing field of research relying on web browsing data. We
                   investigate discrepancies between content obtained directly
                   during user interaction with a website (in-situ) and content
                   scraped using the URLs of participants' logged visits
                   (ex-situ) with various time delays (0, 30, 60, and 90 days).
                   We find substantial disparities between the methodologies,
                   uncovering that errors are not uniformly distributed across
                   news categories regardless of classification method (domain,
                   URL, or content analysis). These biases compromise the
                   precision of measurements used in existing literature. The
                   ex-situ collection environment is the primary source of the
                   discrepancies (~33.8\%), while the time delays in the
                   scraping process play a smaller role (adding ~6.5 percentage
                   points in 90 days). Our research emphasizes the need for data
                   collection methods that capture web content directly in the
                   user's environment. However, acknowledging its complexities,
                   we further explore strategies to mitigate biases in
                   web-scraped browsing histories, offering recommendations for
                   researchers who rely on this method and laying the groundwork
                   for developing error-correction frameworks.",
  month         =  nov,
  year          =  2024,
  archivePrefix = "arXiv"
}

@ARTICLE{Minici2025-mo,
  title         = "{IOHunter}: Graph Foundation Model to Uncover Online
                   Information Operations",
  author        = "Minici, Marco and Luceri, Luca and Fabbri, Francesco and
                   Ferrara, Emilio",
  journal       = "arXiv",
  abstract      = "Social media platforms have become vital spaces for public
                   discourse, serving as modern agor\`as where a wide range of
                   voices influence societal narratives. However, their open
                   nature also makes them vulnerable to exploitation by
                   malicious actors, including state-sponsored entities, who can
                   conduct information operations (IOs) to manipulate public
                   opinion. The spread of misinformation, false news, and
                   misleading claims threatens democratic processes and societal
                   cohesion, making it crucial to develop methods for the timely
                   detection of inauthentic activity to protect the integrity of
                   online discourse. In this work, we introduce a methodology
                   designed to identify users orchestrating information
                   operations, a.k.a. IO drivers, across various influence
                   campaigns. Our framework, named IOHunter, leverages the
                   combined strengths of Language Models and Graph Neural
                   Networks to improve generalization in supervised,
                   scarcely-supervised, and cross-IO contexts. Our approach
                   achieves state-of-the-art performance across multiple sets of
                   IOs originating from six countries, significantly surpassing
                   existing approaches. This research marks a step toward
                   developing Graph Foundation Models specifically tailored for
                   the task of IO detection on social media platforms.",
  month         =  mar,
  year          =  2025,
  archivePrefix = "arXiv"
}

@ARTICLE{Pante2025-pq,
  title         = "Beyond Interaction Patterns: Assessing Claims of Coordinated
                   Inter-State Information Operations on Twitter/{X}",
  author        = "Pantè, Valeria and Axelrod, David and Flammini, Alessandro
                   and Menczer, Filippo and Ferrara, Emilio and Luceri, Luca",
  journal       = "arXiv",
  abstract      = "Social media platforms have become key tools for coordinated
                   influence operations, enabling state actors to manipulate
                   public opinion through strategic, collective actions. While
                   previous research has suggested collaboration between states,
                   such research failed to leverage state-of-the-art
                   coordination indicators or control datasets. In this study,
                   we investigate inter-state coordination by analyzing multiple
                   online behavioral traces and using sophisticated coordination
                   detection models. By incorporating a control dataset to
                   differentiate organic user activity from coordinated efforts,
                   our findings reveal no evidence of inter-state coordination.
                   These results challenge earlier claims and underscore the
                   importance of robust methodologies and control datasets in
                   accurately detecting online coordination.",
  month         =  feb,
  year          =  2025,
  archivePrefix = "arXiv"
}

@ARTICLE{Arora2025-tx,
  title         = "Multi-Modal Framing Analysis of News",
  author        = "Arora, Arnav and Yadav, Srishti and Antoniak, Maria and
                   Belongie, Serge and Augenstein, Isabelle",
  journal       = "arXiv",
  abstract      = "Automated frame analysis of political communication is a
                   popular task in computational social science that is used to
                   study how authors select aspects of a topic to frame its
                   reception. So far, such studies have been narrow, in that
                   they use a fixed set of pre-defined frames and focus only on
                   the text, ignoring the visual contexts in which those texts
                   appear. Especially for framing in the news, this leaves out
                   valuable information about editorial choices, which include
                   not just the written article but also accompanying
                   photographs. To overcome such limitations, we present a
                   method for conducting multi-modal, multi-label framing
                   analysis at scale using large (vision-)language models.
                   Grounding our work in framing theory, we extract latent
                   meaning embedded in images used to convey a certain point and
                   contrast that to the text by comparing the respective frames
                   used. We also identify highly partisan framing of topics with
                   issue-specific frame analysis found in prior qualitative
                   work. We demonstrate a method for doing scalable integrative
                   framing analysis of both text and image in news, providing a
                   more complete picture for understanding media bias.",
  month         =  mar,
  year          =  2025,
  archivePrefix = "arXiv"
}

@ARTICLE{Gaisbauer2025-by,
  title         = "A political cartography of news sharing: Capturing story,
                   outlet and content level of news circulation on Twitter",
  author        = "Gaisbauer, Felix and Pournaki, Armin and Ohme, Jakob",
  journal       = "arXiv",
  abstract      = "News sharing on digital platforms shapes the digital spaces
                   millions of users navigate. Trace data from these platforms
                   also enables researchers to study online news circulation. In
                   this context, research on the types of news shared by users
                   of differential political leaning has received considerable
                   attention. We argue that most existing approaches (i) rely on
                   an overly simplified measurement of political leaning, (ii)
                   consider only the outlet level in their analyses, and/or
                   (iii) study news circulation among partisans by making
                   ex-ante distinctions between partisan and non-partisan news.
                   In this methodological contribution, we introduce a research
                   pipeline that allows a systematic mapping of news sharing
                   both with respect to source and content. As a proof of
                   concept, we demonstrate insights that otherwise remain
                   unnoticed: Diversification of news sharing along the second
                   political dimension; topic-dependent sharing of outlets; some
                   outlets catering different items to different audiences.",
  month         =  may,
  year          =  2025,
  archivePrefix = "arXiv"
}

@ARTICLE{Luceri2025-tr,
  title         = "Coordinated Inauthentic Behavior on {TikTok}: Challenges and
                   Opportunities for Detection in a Video-First Ecosystem",
  author        = "Luceri, Luca and Salkar, Tanishq Vijay and Balasubramanian,
                   Ashwin and Pinto, Gabriela and Sun, Chenning and Ferrara,
                   Emilio",
  journal       = "arXiv",
  abstract      = "Detecting coordinated inauthentic behavior (CIB) is central
                   to the study of online influence operations. However, most
                   methods focus on text-centric platforms, leaving video-first
                   ecosystems like TikTok largely unexplored. To address this
                   gap, we develop and evaluate a computational framework for
                   detecting CIB on TikTok, leveraging a network-based approach
                   adapted to the platform's unique content and interaction
                   structures. Building on existing approaches, we construct
                   user similarity networks based on shared behaviors, including
                   synchronized posting, repeated use of similar captions,
                   multimedia content reuse, and hashtag sequence overlap, and
                   apply graph pruning techniques to identify dense networks of
                   likely coordinated accounts. Analyzing a dataset of 793K
                   TikTok videos related to the 2024 U.S. Presidential Election,
                   we uncover a range of coordinated activities, from
                   synchronized amplification of political narratives to
                   semi-automated content replication using AI-generated
                   voiceovers and split-screen video formats. Our findings show
                   that while traditional coordination indicators generalize
                   well to TikTok, other signals, such as those based on textual
                   similarity of video transcripts or Duet and Stitch
                   interactions, prove ineffective, highlighting the platform's
                   distinct content norms and interaction mechanics. This work
                   provides the first empirical foundation for studying and
                   detecting CIB on TikTok, paving the way for future research
                   into influence operations in short-form video platforms.",
  month         =  may,
  year          =  2025,
  archivePrefix = "arXiv"
}

@ARTICLE{Hartmann2025-px,
  title    = "A systematic review of echo chamber research: comparative analysis
              of conceptualizations, operationalizations, and varying outcomes",
  author   = "Hartmann, David and Wang, Sonja Mei and Pohlmann, Lena and
              Berendt, Bettina",
  journal  = "J. Comput. Soc. Sci.",
  volume   =  8,
  number   =  2,
  pages    =  52,
  abstract = "This systematic review synthesizes research on echo chambers and
              filter bubbles to explore the reasons behind dissent regarding
              their existence, antecedents, and effects. It provides a taxonomy
              of conceptualizations and operationalizations, analyzing how
              measurement approaches and contextual factors influence outcomes.
              The review of 129 studies identifies variations in measurement
              approaches, as well as regional, political, cultural, and
              platform-specific biases, as key factors contributing to the lack
              of consensus. Studies based on homophily and computational social
              science methods often support the echo chamber hypothesis, while
              research on content exposure and broader media environments, such
              as surveys, tends to challenge it. Group behavior, cultural
              influences, instant messaging platforms, and short video platforms
              remain underexplored. The strong geographic focus on the United
              States further highlights the need for studies in multi-party
              systems and regions beyond the Global North. Future research
              should prioritize cross-platform studies, continuous algorithmic
              audits, and investigations into the causal links between
              polarization, fragmentation, and echo chambers to advance the
              field. This review also provides recommendations for using the
              EU’s Digital Services Act to enhance research in this area and
              conduct studies outside the US in multi-party systems. By
              addressing these gaps, this review contributes to a more
              comprehensive understanding of echo chambers, their measurement,
              and their societal impacts.",
  month    =  apr,
  year     =  2025,
  language = "en"
}

@ARTICLE{Green2025-ap,
  title    = "Curation Bubbles",
  author   = "Green, Jon and Mccabe, Stefan and Shugars, Sarah and Chwe, Hanyu
              and Horgan, Luke and Cao, Shuyang and Lazer, David",
  journal  = "Am. Polit. Sci. Rev.",
  pages    = "1--19",
  abstract = "Information on social media is characterized by networked curation
              processes in which users select other users from whom to receive
              information, and those users in turn share information that
              promotes their identities and interests. We argue this allows for
              partisan “curation bubbles” of users who share and consume content
              with consistent appeal drawn from a variety of sources. Yet,
              research concerning the extent of filter bubbles, echo chambers,
              or other forms of politically segregated information consumption
              typically conceptualizes information’s partisan valence at the
              source level as opposed to the story level. This can lead
              domain-level measures of audience partisanship to mischaracterize
              the partisan appeal of sources’ constituent stories—especially for
              sources estimated to be more moderate. Accounting for networked
              curation aligns theory and measurement of political information
              consumption on social media.",
  month    =  jan,
  year     =  2025,
  language = "en"
}

@ARTICLE{Bennett2025-xs,
  title    = "Platforms, Politics, and the Crisis of Democracy: Connective
              Action and the Rise of Illiberalism",
  author   = "Bennett, W Lance and Livingston, Steven",
  journal  = "Perspect. Politics",
  pages    = "1--20",
  abstract = "Democratic backsliding, the slow erosion of institutions,
              processes, and norms, has become more pronounced in many nations.
              Most scholars point to the role of parties, leaders, and
              institutional changes, along with the pursuit of voters through
              what Daniel Ziblatt has characterized as alliances with more
              extremist party surrogate organizations. Although insightful, the
              institutionalist literature offers little reflection about the
              growing role of social technologies in organizing and mobilizing
              extremist networks in ways that present many challenges to
              traditional party gatekeeping, institutional integrity, and other
              democratic principles. We present a more integrated framework that
              explains how digitally networked publics interact with more
              traditional party surrogates and electoral processes to bring
              once-scattered extremist factions into conservative parties. When
              increasingly reactionary parties gain power, they may push both
              institutions and communication processes in illiberal directions.
              We develop a model of communication as networked organization to
              explain how Donald Trump and the Make America Great Again (MAGA)
              movement rapidly transformed the Republican Party in the United
              States, and we point to parallel developments in other nations.",
  month    =  mar,
  year     =  2025,
  language = "en"
}

@ARTICLE{Lai2024-to,
  title    = "Estimating the Ideology of Political {YouTube} Videos",
  author   = "Lai, Angela and Brown, Megan A and Bisbee, James and Tucker,
              Joshua A and Nagler, Jonathan and Bonneau, Richard",
  journal  = "Polit. Anal.",
  volume   =  32,
  number   =  3,
  pages    = "345--360",
  abstract = "We present a method for estimating the ideology of political
              YouTube videos. The subfield of estimating ideology as a latent
              variable has often focused on traditional actors such as
              legislators, while more recent work has used social media data to
              estimate the ideology of ordinary users, political elites, and
              media sources. We build on this work to estimate the ideology of a
              political YouTube video. First, we start with a matrix of
              political Reddit posts linking to YouTube videos and apply
              correspondence analysis to place those videos in an ideological
              space. Second, we train a language model with those estimated
              ideologies as training labels, enabling us to estimate the
              ideologies of videos not posted on Reddit. These predicted
              ideologies are then validated against human labels. We demonstrate
              the utility of this method by applying it to the watch histories
              of survey respondents to evaluate the prevalence of echo chambers
              on YouTube in addition to the association between video ideology
              and viewer engagement. Our approach gives video-level scores based
              only on supplied text metadata, is scalable, and can be easily
              adjusted to account for changes in the ideological landscape.",
  month    =  jul,
  year     =  2024,
  language = "en"
}

@ARTICLE{Mens2025-op,
  title    = "Positioning Political Texts with Large Language Models by Asking
              and Averaging",
  author   = "Mens, Gaël Le and Gallego, Aina",
  journal  = "Polit. Anal.",
  pages    = "1--9",
  abstract = "We use instruction-tuned large language models (LLMs) like GPT-4,
              Llama 3, MiXtral, or Aya to position political texts within policy
              and ideological spaces. We ask an LLM where a tweet or a sentence
              of a political text stands on the focal dimension and take the
              average of the LLM responses to position political actors such as
              US Senators, or longer texts such as UK party manifestos or EU
              policy speeches given in 10 different languages. The correlations
              between the position estimates obtained with the best LLMs and
              benchmarks based on text coding by experts, crowdworkers, or roll
              call votes exceed .90. This approach is generally more accurate
              than the positions obtained with supervised classifiers trained on
              large amounts of research data. Using instruction-tuned LLMs to
              position texts in policy and ideological spaces is fast,
              cost-efficient, reliable, and reproducible (in the case of open
              LLMs) even if the texts are short and written in different
              languages. We conclude with cautionary notes about the need for
              empirical validation.",
  month    =  jan,
  year     =  2025,
  language = "en"
}

@ARTICLE{Budak2024-ef,
  title    = "Misunderstanding the harms of online misinformation",
  author   = "Budak, Ceren and Nyhan, Brendan and Rothschild, David M and
              Thorson, Emily and Watts, Duncan J",
  journal  = "Nature",
  volume   =  630,
  number   =  8015,
  pages    = "45--53",
  abstract = "The controversy over online misinformation and social media has
              opened a gap between public discourse and scientific research.
              Public intellectuals and journalists frequently make sweeping
              claims about the effects of exposure to false content online that
              are inconsistent with much of the current empirical evidence. Here
              we identify three common misperceptions: that average exposure to
              problematic content is high, that algorithms are largely
              responsible for this exposure and that social media is a primary
              cause of broader social problems such as polarization. In our
              review of behavioural science research on online misinformation,
              we document a pattern of low exposure to false and inflammatory
              content that is concentrated among a narrow fringe with strong
              motivations to seek out such information. In response, we
              recommend holding platforms accountable for facilitating exposure
              to false and extreme content in the tails of the distribution,
              where consumption is highest and the risk of real-world harm is
              greatest. We also call for increased platform transparency,
              including collaborations with outside researchers, to better
              evaluate the effects of online misinformation and the most
              effective responses to it. Taking these steps is especially
              important outside the USA and Western Europe, where research and
              data are scant and harms may be more severe.",
  month    =  jun,
  year     =  2024,
  language = "en"
}

@ARTICLE{Yang2025-iv,
  title    = "Coordinated link sharing on Facebook",
  author   = "Yang, Yunkang and Paudel, Ramesh and McShan, Jordan and Hindman,
              Matthew and Huang, H Howie and Broniatowski, David",
  journal  = "Sci. Rep.",
  volume   =  15,
  number   =  1,
  pages    =  15684,
  abstract = "Malicious actors regularly attempt to manipulate social media
              using coordinated posting. Many existing methods for detecting
              this coordination, though, have relied primarily on post-timing,
              which is trivially easy to change. In this paper, we make a
              significant methodological advancement in coordination detection,
              leveraging highly regular statistical patterns in the speed and
              frequency of sharing. We apply and validate this approach on
              Facebook, using 11.2 million link posts from a list of 16,169 most
              popular English-language Facebook pages that referenced at least
              one of the top eight US politicians in any post, a set of pages
              that produced more than 91\% of all user engagement in this
              category during our collection period. Our approach can be
              calibrated and adapted across contexts, platforms, and times,
              allowing researchers to build valid, testable, but still
              human-interpretable models of platform manipulations.",
  month    =  may,
  year     =  2025,
  language = "en"
}

@ARTICLE{Votta2024-qz,
  title    = "The Cost of Reach: Testing the Role of Ad Delivery Algorithms in
              Online Political Campaigns",
  author   = "Votta, Fabio and Dobber, Tom and Guinaudeau, Benjamin and
              Helberger, Natali and De Vreese, Claes",
  journal  = "Polit. Commun.",
  pages    = "1--33",
  month    =  dec,
  year     =  2024,
  language = "en"
}

@ARTICLE{Munger2024-bl,
  title    = "What Did We Learn About Political Communication from the
              {Meta2020} Partnership?",
  author   = "Munger, Kevin",
  journal  = "Polit. Commun.",
  pages    = "1--7",
  month    =  dec,
  year     =  2024,
  language = "en"
}

@ARTICLE{Gattermann2025-yx,
  title    = "The role of far-right party performance in shaping disinformation
              concerns of European voters: evidence from the 2024 European
              Parliament elections",
  author   = "Gattermann, Katjana and Van Den Hoogen, Elske and De Vreese, Claes",
  journal  = "J. Eur. Public Policy",
  pages    = "1--26",
  month    =  apr,
  year     =  2025,
  language = "en"
}

@ARTICLE{Righetti2025-zm,
  title    = "Mainstreaming and transnationalization of anti-gender ideas
              through social media: the case of {CitizenGO}",
  author   = "Righetti, Nicola and Kulichkina, Aytalina and Almeida Paroni,
              Bruna and Cseri, Zsofia Fanni and Aguirre, Sofia Iriarte and
              Maikovska, Kateryna",
  journal  = "Inf. Commun. Soc.",
  pages    = "1--24",
  month    =  feb,
  year     =  2025,
  language = "en"
}

@ARTICLE{Graham2025-gp,
  title    = "How propaganda exploits the infrastructure of truth: A case study
              of \#IStandWithPutin",
  author   = "Graham, Timothy",
  journal  = "Crit. Stud. Media Commun.",
  pages    = "1--8",
  month    =  mar,
  year     =  2025,
  language = "en"
}

@ARTICLE{McNally2025-dn,
  title    = "The News Feed is not a Black Box: A Longitudinal Study of
              Facebook’s Algorithmic Treatment of News",
  author   = "McNally, N and Bastos, M",
  journal  = "Digit. Journal.",
  abstract = "This study examines the effects of a series of significant
              algorithm changes within Facebook’s News Feed on user engagement
              with news content on the platform between 2011-2020. By tracking
              public announcements, industry research, and leaks to the press,
              we constructed a timeline of algorithm changes and collected data
              on 1 million news articles from The Guardian over the 10-year
              period, alongside their associated Facebook engagement metrics
              (likes, comments, shares, etc.) using the CrowdTangle API. Using
              time series analysis techniques including cross-correlation,
              Granger causality, and anomaly detection, we modeled this data to
              test for the relationship between significant algorithmic ranking
              updates to Facebook’s News Feed algorithms and user engagement
              with Guardian articles on the platform. Our results show that
              strategic interventions to the News Feed algorithm significantly
              impacted engagement with hard news items, whereas opinion,
              lifestyle, sports, and arts content were less affected. This study
              challenges the notion of algorithms as ‘black boxes’ by
              demonstrating how Facebook’s deliberate adjustments influence user
              engagement with news content. We conclude by outlining the
              limitations and challenges for systemic auditing of social media
              algorithms, advocating for greater data access, and discussing the
              opportunities afforded by the EU’s Digital Services Act to advance
              this research agenda.",
  month    =  jan,
  year     =  2025,
  language = "en"
}

@ARTICLE{Smith2025-kc,
  title    = "Emergent structures of attention on social media are driven by
              amplification and triad transitivity",
  author   = "Smith, Alyssa Hasegawa and Green, Jon and Foucault Welles, Brooke
              and Lazer, David",
  journal  = "PNAS Nexus",
  pages    = "gaf106",
  abstract = "Abstract As they evolve, social networks tend to form transitive
              triads more often than random chance and structural constraints
              would suggest. However, the mechanisms by which triads in these
              networks become transitive are largely unexplored. We leverage a
              unique combination of data and methods to demonstrate a causal
              link between amplification and triad transitivity in a directed
              social network. Additionally, we develop the concept of the
              ``attention broker, '' an extension of the previously theorized
              tertius iungens (or ``third who joins’'). We use a novel technique
              to identify time-bounded Twitter/X following events, and then use
              difference-in-differences to show that attention brokers cause
              triad transitivity by amplifying content. Attention brokers
              intervene in the evolution of any sociotechnical system where
              individuals can amplify content while referencing its originator.",
  month    =  apr,
  year     =  2025,
  language = "en"
}

@ARTICLE{Bakshy2015-rn,
  title    = "Exposure to ideologically diverse news and opinion on Facebook",
  author   = "Bakshy, Eytan and Messing, Solomon and Adamic, Lada A",
  journal  = "Science",
  volume   =  348,
  number   =  6239,
  pages    = "1130--1132",
  abstract = "Exposure to news, opinion, and civic information increasingly
              occurs through social media. How do these online networks
              influence exposure to perspectives that cut across ideological
              lines? Using deidentified data, we examined how 10.1 million U.S.
              Facebook users interact with socially shared news. We directly
              measured ideological homophily in friend networks and examined the
              extent to which heterogeneous friends could potentially expose
              individuals to cross-cutting content. We then quantified the
              extent to which individuals encounter comparatively more or less
              diverse content while interacting via Facebook’s algorithmically
              ranked News Feed and further studied users’ choices to click
              through to ideologically discordant content. Compared with
              algorithmic ranking, individuals’ choices played a stronger role
              in limiting exposure to cross-cutting content.",
  month    =  jun,
  year     =  2015,
  keywords = "facebook; homophily; news; newsfeed"
}

@ARTICLE{Sarmiento2025-as,
  title    = "Unsupervised Framing Analysis for Social Media Discourse in
              Polarizing Events",
  author   = "Sarmiento, Hernan and Córdova, Ricardo and Ortiz, Jorge and
              Bravo-Marquez, Felipe and Santos, Marcelo and Valenzuela,
              Sebastián",
  journal  = "ACM Trans. Web",
  pages    =  3711912,
  abstract = "This study investigates the concept of frames in the realm of
              online polarization, with a focus on social media platforms. The
              research extends the understanding of how frames—emerging,
              complex, and often subtle concepts—become prominent in online
              conversations that are polarized. The study proposes a
              comprehensive methodology for identifying and characterizing these
              frames, integrating machine learning techniques, network analysis
              algorithms, and natural language processing tools. This method
              aims for generalizability across multiple platforms and types of
              user engagement. Two novel metrics, homogeneity and relevancy are
              introduced for the rigorous evaluation of identified frame
              candidates. Grounded in several foundational presumptions,
              including the role of topics and multi-word expressions in
              framing, the study sheds light on how frames emerge and gain
              significance within digital communities. The research questions
              explored include the methods for identifying frames, the
              variability and significance of these frames, and the
              effectiveness of different computational techniques in this
              context. To validate the approach, we present a case study of the
              2021 Chilean presidential election, using data from both Twitter
              and WhatsApp platforms. This real-world application allows for the
              examination of how frames fluctuate in response to events and the
              specific mechanisms of platforms. Overall, the study makes several
              key contributions to the field, offering new insights and
              methodologies for analyzing the complexities of online
              polarization. It serves as groundwork for future research on the
              dynamics of online communities, especially those associated with
              distinctly polarized events.",
  month    =  jan,
  year     =  2025,
  language = "en"
}

@ARTICLE{Hurcombe2025-cs,
  title    = "The discursive function of Meta’s Newsroom: How Meta frames the
              problem of problematic online content",
  author   = "Hurcombe, Edward and Dehghan, Ehsan and Vodden, Laura and Angus,
              Daniel",
  journal  = "Converg. Int. J. Res. New Media Technol.",
  pages    =  13548565251315521,
  abstract = "This article examines the social technology company Meta’s public
              communication on problematic content, via their official ‘Meta
              Newsroom’, within the context of growing regulatory scrutiny. For
              nearly a decade, the Meta Newsroom has been a major outlet for
              Meta company announcements, and since 2016, the Newsroom has
              increasingly become a key source for company responses to concerns
              regarding mis/disinformation and other kinds of problematic
              content on Meta’s platforms. Using a mixed-methods approach
              informed by discourse analysis, this article critically examines
              Newsrooms posts from 2016 to early 2021. It asks: how is Meta
              framing ‘problems’ on its platforms? How is Meta identifying
              ‘solutions’ to those problems? And is Meta ‘nudging’ policymakers
              in specific conceptual directions? Overall, we find that Meta is
              framing content moderation issues through four key frames –
              ‘authenticity’, ‘political advertising’, ‘technological
              solutions’, and ‘enforcement’ – that benefit Meta, as they shift
              responsibility while also demonstrating that Meta is an active and
              capable problem-solver.",
  month    =  feb,
  year     =  2025,
  language = "en"
}

@ARTICLE{Cabbuag2024-me,
  title    = "Tiktok ‘dogshows’ and the amplification of online incivility among
              Gen {Z} influencers in the Philippines",
  author   = "Cabbuag, Samuel I and Abidin, Crystal",
  journal  = "Int. J. Cult. Stud.",
  pages    =  13678779241302826,
  abstract = "Studies on digital platforms and online incivility have
              established that uses of humour can lean towards cyberbullying and
              hate speech. Focusing on TikTok's affordances and cultures of
              online incivility, this paper studies how TikTok influencers and
              their audiences manoeuvre legal-but-harmful humour. Specifically,
              we study how online incivility has become an accepted and
              negotiated practice in the Filipino context through the phenomenon
              of ‘dogshows’, where users throw jabs at individuals using
              derogatory humour and provocative memes. Through online
              observation and textual analysis of TikTok posts and their
              corresponding comment sections, we demonstrate how online
              incivility is subtly amplified through humour and play, and how
              Gen Z and young children became both objects and producers of
              these dogshows. We argue that while there is already peer
              surveillance at work on TikTok, there needs to be more
              deliberation between TikTok's policies and at-risk groups to make
              the platform a more civil space.",
  month    =  dec,
  year     =  2024,
  language = "en"
}

@ARTICLE{Bosch2024-hj,
  title    = "The sound of disinformation: {TikTok}, computational propaganda,
              and the invasion of Ukraine",
  author   = "Bösch, Marcus and Divon, Tom",
  journal  = "New Media Soc.",
  volume   =  26,
  number   =  9,
  pages    = "5081--5106",
  abstract = "TikTok has emerged as a powerful platform for the dissemination of
              mis- and disinformation about the war in Ukraine. During the
              initial three months after the Russian invasion in February 2022,
              videos under the hashtag \#Ukraine garnered 36.9 billion views,
              with individual videos scaling up to 88 million views. Beyond the
              traditional methods of spreading misleading information through
              images and text, the medium of sound has emerged as a novel,
              platform-specific audiovisual technique. Our analysis
              distinguishes various war-related sounds utilized by both Ukraine
              and Russia and classifies them into a mis- and disinformation
              typology. We use computational propaganda features—automation,
              scalability, and anonymity—to explore how TikTok’s auditory
              practices are exploited to exacerbate information disorders in the
              context of ongoing war events. These practices include reusing
              sounds for coordinated campaigns, creating audio meme templates
              for rapid amplification and distribution, and deleting the
              original sounds to conceal the orchestrators’ identities. We
              conclude that TikTok’s recommendation system (the “for you” page)
              acts as a sound space where exposure is strategically navigated
              through users’ intervention, enabling semi-automated “soft”
              propaganda to thrive by leveraging its audio features.",
  year     =  2024,
  language = "en"
}

@ARTICLE{Gagrcin2024-dl,
  title    = "Algorithmic media use and algorithm literacy: An integrative
              literature review",
  author   = "Gagrčin, Emilija and Naab, Teresa K and Grub, Maria F",
  journal  = "New Media Soc.",
  pages    =  14614448241291137,
  abstract = "Algorithms profoundly shape user experiences on digital platforms,
              raising concerns about their negative impacts and highlighting the
              importance of algorithm literacy. Research on individuals’
              understanding of algorithms and their effects is expanding rapidly
              but lacks a cohesive framework. We conducted a systematic
              integrative literature review across social sciences and
              humanities (n = 169), addressing algorithm literacy in terms of
              its key conceptualizations and the endogenous, exogenous, and
              personal factors that influence it. We argue that existing
              research can be framed in terms of experiential learning cycles
              and outline how this approach can be beneficial for acquiring
              algorithm literacy. Finally, we propose a future research agenda
              that includes defining core competencies relevant to algorithm
              literacy, standardization of measures, integrating subjective and
              factual aspects of algorithm literacy, and task- and
              domain-specific approaches.",
  month    =  nov,
  year     =  2024,
  language = "en"
}

@ARTICLE{Tornberg2025-ir,
  title    = "When Do Parties Lie? Misinformation and Radical-Right Populism
              Across 26 Countries",
  author   = "Törnberg, Petter and Chueri, Juliana",
  journal  = "Int. J. Press Polit.",
  pages    =  19401612241311886,
  abstract = "The spread of misinformation has emerged as a global concern.
              Academic attention has recently shifted to emphasize the role of
              political elites as drivers of misinformation. Yet, little is
              known of the relationship between party politics and the spread of
              misinformation—in part due to a dearth of cross-national empirical
              data needed for comparative study. This article examines which
              parties are more likely to spread misinformation, by drawing on a
              comprehensive database of 32M tweets from parliamentarians in 26
              countries, spanning 6 years and several election periods. The
              dataset is combined with external databases such as Parlgov and
              V-Dem, linking the spread of misinformation to detailed
              information about political parties and cabinets, thus enabling a
              comparative politics approach to misinformation. Using multilevel
              analysis with random country intercepts, we find that
              radical-right populism is the strongest determinant for the
              propensity to spread misinformation. Populism, left-wing populism,
              and right-wing politics are not linked to the spread of
              misinformation. These results suggest that political
              misinformation should be understood as part and parcel of the
              current wave of radical right populism, and its opposition to
              liberal democratic institution.",
  month    =  jan,
  year     =  2025,
  language = "en"
}

@ARTICLE{Nenno2025-xa,
  title    = "All The (Fake) News That’s Fit to Share? News Values in Perceived
              Misinformation across Twenty-Four Countries",
  author   = "Nenno, Sami and Puschmann, Cornelius",
  journal  = "Int. J. Press Polit.",
  pages    =  19401612241311893,
  abstract = "While there is a strong scholarly interest surrounding the content
              of political misinformation online, much of this research concerns
              misinformation in Western, Educated, Industrialized, Rich and
              Democratic (WEIRD) countries. Although such research has
              investigated the topical and stylistic characteristics of
              misinformation, its findings are frequently not interpreted
              systematically in relation to properties that journalists rely on
              to capture the attention of audiences, that is, in relation to
              news values. We close the gap on comparative studies of news
              values in misinformation with a perspective that emphasizes
              non-WEIRD countries. Relying on a dataset of URLs that were shared
              on Facebook in twenty-four countries and reported by users as
              containing false news, we compile a large corpus of online news
              items and use an array of computational tools to analyze its
              content with respect to a set of five news values (conflict,
              negativity, proximity, individualization, and informativeness). We
              find salient differences for almost all news values and regarding
              the WEIRD/non-WEIRD and flagged/unflagged distinction. Moreover,
              the prevalence of individual news values differs strongly for
              individual countries. However, while almost all differences are
              significant, the effects we encounter are mostly small.",
  month    =  jan,
  year     =  2025,
  language = "en"
}

@ARTICLE{Humprecht2025-ml,
  title    = "Advancing the Study of Political Misinformation Across Countries
              and {Platforms—Introduction} to the Special Issue",
  author   = "Humprecht, Edda and Valenzuela, Sebastián and Esser, Frank and
              Tandoc, Edson",
  journal  = "Int. J. Press Polit.",
  pages    =  19401612251327530,
  abstract = "The global spread of political misinformation poses serious
              challenges to democracies, eroding trust and distorting public
              discourse. However, research has largely focused on WEIRD
              countries—Western, Educated, Industrialized, Rich, and
              Democratic—limiting our understanding of how misinformation
              operates across diverse political, cultural, and technological
              contexts. This special issue addresses these gaps through
              comparative, cross-platform, and interdisciplinary perspectives.
              The articles explore how political and media systems shape
              misinformation, the role of individual resilience, and how
              platform-specific features—across social media, messaging apps,
              and traditional media—affect the spread of false information.
              Studies from non-WEIRD regions offer insights into distinct
              vulnerabilities, emphasizing the need for context-sensitive
              approaches. Together, these contributions advance our
              understanding of misinformation as a global challenge and offer
              guidance for strengthening democratic resilience in varied
              information environments.",
  month    =  mar,
  year     =  2025,
  language = "en"
}

@ARTICLE{Xue2025-bp,
  title    = "Facts or Feelings? Leveraging Emotionality as a Fact-Checking
              Strategy on Social Media in the United States",
  author   = "Xue, Haoning and Zhang, Jingwen and Zhang, Xinzhi",
  journal  = "Soc. Media Soc.",
  volume   =  11,
  number   =  1,
  pages    =  20563051251318172,
  abstract = "Emotionality is a well-established strategy for boosting audience
              engagement on social media. While fact-checking is positioned to
              provide objective information, fact-checking posts on social media
              often involve heightened emotionality. How much emotionality is
              present and how emotionality influences audience engagement and
              public sentiment toward fact-checked targets remain largely
              understudied. Informed by social psychological frameworks
              explicating message-level factors influencing public engagement
              and sentiment, the present study examines emotionality in 49,270
              fact-checking posts created by 10 United States fact-checking
              organizations on Facebook from 2017 to 2022. Results showed that
              emotionality in fact-checking posts significantly increased by
              13.5\% over the years. Editorial fact-checkers (e.g., Washington
              Post) used higher levels of emotionality than independent
              fact-checkers (e.g., snopes.com). Emotionality positively
              indicated public engagement as predicted. However, in both
              fact-checked true and false information, emotionality was
              negatively associated with the public’s sentiment toward
              fact-checked targets, suggesting a potential spillover effect on
              stories verified to be true. This study reveals that emotionality
              in fact-checking posts boosts social media engagement yet with the
              potential of compromising fact-checking effectiveness.",
  year     =  2025,
  language = "en"
}

@ARTICLE{Bastos2025-ol,
  title    = "Visual Identities in Troll Farms: The Twitter Moderation Research
              Consortium",
  author   = "Bastos, Marco",
  journal  = "Soc. Media Soc.",
  volume   =  11,
  number   =  1,
  pages    =  20563051251323652,
  abstract = "The Twitter Moderation Research Consortium is a database of
              network propaganda and influence operations that includes 115,474
              unique Twitter accounts, millions of tweets, and over one terabyte
              of media removed from the platform between 2017 and 2022. We probe
              this database using Google’s Vision API and Keras with TensorFlow
              to test whether foreign influence operations can be identified
              based on the visual presentation of fake user profiles emphasizing
              gender, race, camera angle, sensuality, and emotion. Our results
              show that sensuality is a variable associated with operations that
              replicate the Kremlin-linked Internet Research Agency campaign,
              being particularly prevalent in influence operations that targeted
              communities in North and South America, but also in Indonesia,
              Turkey, and Pakistan. Our results also show that the visual
              identities of fake social media profiles are predictive of
              influence operations given their reliance on selfies, sensual
              young women, K-pop aesthetics, or alternatively nationalistic
              iconography overlaid with text to convey ideological positioning.",
  year     =  2025,
  language = "en"
}

@ARTICLE{Bruns2025-fz,
  title    = "Untangling the Furball: A Practice Mapping Approach to the
              Analysis of Multimodal Interactions in Social Networks",
  author   = "Bruns, Axel and Kasianenko, Kateryna and Suresh, Vish
              Padinjaredath and Dehghan, Ehsan and Vodden, Laura",
  journal  = "Soc. Media Soc.",
  volume   =  11,
  number   =  2,
  pages    =  20563051251331748,
  abstract = "This article introduces the analytical approach of practice
              mapping , using vector embeddings of network actions and
              interactions to map commonalities and disjunctures in the
              practices of social media users, as a framework for methodological
              advancement beyond the limitations of conventional network
              analysis and visualization. In particular, the methodological
              framework we outline here has the potential to incorporate
              multiple distinct modes of interaction into a single practice map;
              can be further enriched with account-level attributes such as
              information gleaned from textual analysis, profile information,
              available demographic details, and other features; and can be
              applied even to a cross-platform analysis of communicative
              patterns and practices. The article presents practice mapping as
              an analytical framework and outlines its key methodological
              considerations. Given its prominence in past social media
              research, we draw on examples and data from the platform formerly
              known as Twitter to enable experienced scholars to translate their
              approaches to a practice mapping paradigm more easily, but point
              out how data from other platforms may be used in equivalent ways
              in practice mapping studies. We illustrate the utility of the
              approach by applying it to a dataset where the application of
              conventional network analysis and visualization approaches has
              produced few meaningful insights.",
  year     =  2025,
  language = "en"
}

@ARTICLE{Esau2025-tf,
  title    = "The Quality of Connections: Deliberative Reciprocity and Inclusive
              Listening as Antidote to Destructive Polarization Online",
  author   = "Esau, Katharina",
  journal  = "Soc. Media Soc.",
  volume   =  11,
  number   =  2,
  pages    =  20563051251332421,
  abstract = "Conflict and disagreement are integral to healthy democracies, but
              the extreme polarization observed on many social media platforms
              poses a serious risk to the core functions of public
              communication. This theoretical article draws on the concept of
              connective democracy, further theorizing it to bridge the gap
              between empirical online deliberation and polarization research.
              It introduces and refines the concept of destructive polarization
              and its symptoms—manifested in user-generated content on social
              media platforms—and applies connective democracy theory to examine
              these symptoms’ underlying causes. The framework shifts from the
              dominant focus on the quality of individual communication acts to
              a focus on the quality of connections, particularly within dyadic
              communication. Through this relational perspective, the article
              explores how reciprocity and listening can serve as remedies to
              destructive polarization, fostering high-quality connections
              between citizens online. Reciprocity and listening are discussed
              as communicative mechanisms that should be nurtured as part of
              depolarization strategies. Finally, the article offers insights
              into what platform providers and community managers can learn from
              this theoretical exercise to promote democratic discourse online.",
  year     =  2025,
  language = "en"
}

@ARTICLE{Simeone2025-vo,
  title    = "Network Ripple Effects: How Twitter Deplatforming Flipped
              Authority Structure and Discourse of the Arizona Election Review
              Community",
  author   = "Simeone, Michael and Corman, Steven R",
  journal  = "SAGE Open",
  volume   =  15,
  number   =  1,
  pages    =  21582440251314538,
  abstract = "Content moderation decisions can have variable impacts on the
              events and discourses they aim to regulate. This study analyzes
              Twitter data from before and after the removal of key Arizona
              Election Audit Twitter accounts in March of 2021. After collecting
              tweets that refer to the election audit in Arizona in this
              designated timeframe, a before/after comparison examines the
              structure of the networks, the volume of the participating
              population, and the themes of their discourse. Several significant
              changes are observed, including a drop in participation from
              accounts that were not deplatformed and a de-centralization of the
              Twitter network. Conspiracy theories remain in the discourse, but
              their themes become more diffuse, and their calls to action more
              abstract. Recruiting calls to join in on promoting and publicizing
              the audit mostly come to an end. The decision by Twitter to
              deplatform key election audit accounts appears to have greatly
              disrupted the hub structure at the center of the emergent network
              that formed as a response to the election audit. By intervening in
              the network, moderators successfully defused much of the
              Twitter-based participation in the Arizona Election Review of
              2021. This instance demonstrates the efficacy of network-driven
              interventions in platform moderation, specifically for events or
              accounts that use social media to organize or encourage bad-faith
              attacks on civic instituions. , Plain language summary The impact
              of removing twitter accounts: How it changed the power and
              conversations in the Arizona election review community This
              research looks at how decisions to control content online can
              affect discussions and events. The study focuses on Twitter and
              examines data before and after certain Arizona Election Audit
              accounts were removed in March 2021. The analysis compares the
              structure of Twitter networks, the number of people involved, and
              the topics discussed. The study finds significant changes, such as
              fewer contributions from accounts that weren’t removed and a less
              centralized Twitter network. While conspiracy theories still come
              up, they become more scattered, and calls to action become less
              direct. The study suggests that Twitter’s decision to remove key
              accounts disrupted the central structure of the emerging network
              related to the election audit. By doing this, the platform
              moderators reduced participation in the Arizona Election Review of
              2021 on Twitter. This research shows that interventions in social
              media networks can be effective in moderating discussions,
              especially for events or accounts linked to misleading users en
              route to encouraging political instability.",
  year     =  2025,
  language = "en"
}

@ARTICLE{Gonzalez-Bailon2024-rq,
  title    = "The Diffusion and Reach of (Mis)Information on Facebook During the
              {U}.{S}. 2020 Election",
  author   = "González-Bailón, Sandra and Lazer, David and Barberá, Pablo and
              Godel, William and Allcott, Hunt and Brown, Taylor and
              Crespo-Tenorio, Adriana and Freelon, Deen and Gentzkow, Matthew
              and Guess, Andrew M and Iyengar, Shanto and Kim, Young Mie and
              Malhotra, Neil and Moehler, Devra and Nyhan, Brendan and Pan,
              Jennifer and Rivera, Carlos Velasco and Settle, Jaime and Thorson,
              Emily and Tromble, Rebekah and Wilkins, Arjun and Wojcieszak,
              Magdalena and Kiewiet de Jonge, Chad and Franco, Annie and Mason,
              Winter and Stroud, Natalie Jomini and Tucker, Joshua A",
  journal  = "Sociol. Sci.",
  volume   =  11,
  pages    = "1124--1146",
  abstract = "Social media creates the possibility for rapid, viral spread of
              content, but how many posts actually reach millions? And is
              misinformation special in how it propagates? We answer these
              questions by analyzing the virality of and exposure to information
              on Facebook during the U.S. 2020 presidential election. We examine
              the diffusion trees of the approximately 1 B posts that were
              re-shared at least once by U.S.-based adults from July 1, 2020, to
              February 1, 2021. We differentiate misinformation from
              non-misinformation posts to show that (1) misinformation diffused
              more slowly, relying on a small number of active users that spread
              misinformation via long chains of peer-to-peer diffusion that
              reached millions; non-misinformation spread primarily through
              one-to-many affordances (mainly, Pages); (2) the relative
              importance of peer-to-peer spread for misinformation was likely
              due to an enforcement gap in content moderation policies designed
              to target mostly Pages and Groups; and (3) periods of aggressive
              content moderation proximate to the election coincide with
              dramatic drops in the spread and reach of misinformation and (to a
              lesser extent) political content.",
  month    =  dec,
  year     =  2024,
  language = "en"
}

@ARTICLE{Righetti2025-pt,
  title    = "{CooRTweet}: A Generalized {R} Software for Coordinated Network
              Detection",
  author   = "Righetti, Nicola and Balluff, Paul",
  abstract = "This paper introduces CooRTweet, an innovative R package designed
              for detecting and analyzing coordinated behavior. CooRTweet
              represents the first R tool capable of detecting coordinated
              networks sharing various types of content across different
              platforms, including cross-platform activities. The flexibility of
              CooRTweet addresses certain limitations inherent in current
              threshold-based methodologies. Its approach facilitates a more
              profound analysis of networks, offering a comprehensive view of
              coordinated activities that include both explicit coordination and
              organic forms of content sharing, marking an advancement in
              studying coordinated networks. This methodology is particularly
              pertinent for thoroughly understanding networks involved in
              disseminating misinformation, fake news, and digital propaganda.
              The comprehensive architecture of CooRTweet provides flexibility
              and a broad scope for analyzing coordinated activities across
              various digital landscapes. This positions it as a distinctive
              resource for researchers investigating coordinated communication
              on social media. This paper aims to provide an introduction to
              CooRTweet and the analysis of coordinated behavior, demonstrating
              the software's application through a case study of cross-platform
              coordinated behavior during the 2021 German elections.",
  month    =  mar,
  year     =  2025
}

@ARTICLE{Mosleh2024-op,
  title         = "Divergent patterns of engagement with partisan and
                   low-quality news across seven social media platforms",
  author        = "Mosleh, Mohsen and Allen, Jennifer Nancy Lee and Rand, David
                   Gertler",
  journal       = "PsyArXiv",
  abstract      = "In recent years, social media has become increasingly
                   fragmented, as platforms evolve and new alternatives emerge.
                   Yet most research studies a single platform—typically
                   Twitter/X, or occasionally Facebook—leaving little known
                   about the broader social media landscape. Here we shed new
                   light on patterns of cross-platform variation in the
                   high-stakes context of news sharing. We examine the
                   relationship between user engagement and news domains’
                   political orientation and quality across seven platforms:
                   Twitter/X, BlueSky, TruthSocial, Gab, GETTR, Mastodon, and
                   LinkedIn. Using an exhaustive sampling strategy, we analyze
                   all (over 10 million) posts containing links to news domains
                   shared on these platforms during January 2024. We find that
                   the news shared on platforms with more conservative user
                   bases is significantly lower quality on average. Turning to
                   patterns of engagement, we find—contrary to hypotheses of a
                   consistent “right wing advantage” on social media—that the
                   relationship between political lean and engagement is
                   strongly heterogeneous across platforms. Conservative new
                   posts receive more engagement on platforms where most content
                   is conservative, and vice versa for liberal news posts,
                   consistent with an “echo platform” perspective. In contrast,
                   the relationship between news quality and engagement is
                   strikingly consistent: across all platforms examined,
                   lower-quality news posts received higher average engagement
                   even though higher quality news is substantially more
                   prevalent and garners far more total engagement across posts.
                   This pattern holds despite accounting for poster-level
                   variation, and is observed even in the absence of ranking
                   algorithms, suggesting user preferences – not algorithmic –
                   bias may underlie the underperformance of higher-quality
                   news.",
  month         =  dec,
  year          =  2024,
  archivePrefix = "PsyArXiv"
}

@ARTICLE{DiGiuseppe2025-es,
  title    = "Scaling Open-ended Survey Responses Using {LLM}-Paired Comparisons",
  author   = "DiGiuseppe, Matthew and Flynn, Michael E",
  abstract = "Survey researchers rely heavily on closed-ended questions to
              measure latent respondent characteristics like knowledge, policy
              positions, emotions, ideology, and various other traits. While
              closed-ended questions ease analysis and data collection, they
              necessarily limit the depth and variability of responses.
              Open-ended responses allow for greater depth and variability in
              responses but are labor-intensive to code. Large Language Models
              (LLMs) can solve some of these problems, but existing approaches
              to using LLMs have a number of limitations. In this paper, we
              propose and test a pairwise comparison method to scale open-ended
              survey responses on a continuous scale. The approach relies on
              LLMs to make pairwise comparisons of statements that identify
              which statement ``wins'' and ``loses''. With this information, we
              employ a Bayesian Bradley-Terry model to recover a `score' on a
              the relevant latent dimension for each statement. This approach
              allows for finer discrimination between items, better measures of
              uncertainty, reduces anchoring bias, and is more flexible than
              methods relying on Maximum Likelihood Estimation techniques. We
              demonstrate the utility of this approach on an open-ended question
              probing knowledge of interest rates in the US economy. A
              comparison of 6 LLMs of various sizes reveals that pairwise
              comparisons show greater consistency than zero-shot 0-10 ratings
              with larger models (> 9-billion parameters). Further, comparison
              of pairwise decisions are consistent with high-knowledge crowd
              source workers.",
  month    =  jan,
  year     =  2025
}

@ARTICLE{Kristensen2025-ni,
  title   = "Platform Polarization. Do Alternative Platforms Drive Discursive
             Polarization?",
  author  = "Kristensen, Jakob Bæk and Kristensen, Jakob Bæk",
  journal = "Comun. Politica",
  number  = "1/2025",
  year    =  2025
}

@ARTICLE{Allcott2025-jb,
  title         = "The Effects of Political Advertising on Facebook and
                   Instagram before the 2020 {US} Election",
  author        = "Allcott, Hunt and Gentzkow, Matthew and Levy, Ro'ee and
                   Crespo-Tenorio, Adriana and Dumas, Natasha and Mason, Winter
                   and Moehler, Devra and Barbera, Pablo and Brown, Taylor W and
                   Cisneros, Juan Carlos and Dimmery, Drew and Freelon, Deen and
                   González-Bailón, Sandra and Guess, Andrew M and Kim, Young
                   Mie and Lazer, David and Malhotra, Neil and Nair-Desai,
                   Sameer and Nyhan, Brendan and Paixao de Queiroz, Ana Carolina
                   and Pan, Jennifer and Settle, Jaime and Thorson, Emily and
                   Tromble, Rebekah and Velasco Rivera, Carlos and Wittenbrink,
                   Benjamin and Wojcieszak, Magdalena and Yang, Shiqi and
                   Zahedian, Saam and Franco, Annie and Kiewiet de Jonge, Chad
                   and Jomini Stroud, Natalie and Tucker, Joshua A",
  journal       = "National Bureau of Economic Research",
  abstract      = "We study the effects of social media political advertising by
                   randomizing subsets of 36,906 Facebook users and 25,925
                   Instagram users to have political ads removed from their news
                   feeds for six weeks before the 2020 US presidential election.
                   We show that most presidential ads were targeted toward
                   parties’ own supporters and that fundraising ads were most
                   common. On both Facebook and Instagram, we found no
                   detectable effects of removing political ads on political
                   knowledge, polarization, perceived legitimacy of the
                   election, political participation (including campaign
                   contributions), candidate favorability, and turnout. This was
                   true overall and for both Democrats and Republicans
                   separately.",
  series        = "Working Paper Series",
  month         =  may,
  year          =  2025,
  archivePrefix = "National Bureau of Economic Research"
}

@ARTICLE{Luhring2025-od,
  title    = "Best practices for source-based research on misinformation and
              news trustworthiness using {NewsGuard}",
  author   = "Lühring, Jula and Metzler, Hannah and Lazzaroni, Ruggero and
              Shetty, Apeksha and Lasser, Jana",
  journal  = "J. Quant. Descr. Digit. Media",
  volume   =  5,
  abstract = "Researchers need reliable and valid tools to identify cases of
              untrustworthy information when studying the spread of
              misinformation on digital platforms. A common approach is to
              assess the trustworthiness of sources rather than individual
              pieces of content. One of the most widely used and comprehensive
              databases for source trustworthiness ratings is provided by
              NewsGuard. Since creating the database in 2019, NewsGuard has
              continually added new sources and reassessed existing ones. While
              NewsGuard initially focused only on the US, the database has
              expanded to include sources from other countries. In addition to
              trustworthiness ratings, the NewsGuard database contains various
              contextual assessments of the sources, which are less often used
              in contemporary research on misinformation. In this work, we
              provide an analysis of the content of the NewsGuard database,
              focusing on the temporal stability and completeness of its ratings
              across countries, as well as the usefulness of information on
              political orientation and topics for misinformation studies. We
              find that trustworthiness ratings and source coverage have
              remained relatively stable since 2022, particularly for the US,
              France, Italy, Germany, and Canada, with US-based sources
              consistently scoring lower than those from other countries.
              Additional information on the political orientation and topics
              covered by sources is comprehensive and provides valuable assets
              for characterizing sources beyond trustworthiness. By evaluating
              the database over time and across countries, we identify potential
              pitfalls that compromise the validity of using NewsGuard as a tool
              for quantifying untrustworthy information, particularly if
              dichotomous ``trustworthy''/``untrustworthy'' labels are used.
              Lastly, we provide recommendations for digital media research on
              how to avoid these pitfalls and discuss appropriate use cases for
              the NewsGuard database and source-level approaches in general.",
  month    =  jan,
  year     =  2025,
  language = "en"
}

@ARTICLE{Gaw2025-ru,
  title    = "Influence Operations as Brokerage: Political-Economic
              Infrastructures of Manipulation in the 2022 Philippine Elections",
  author   = "Gaw, Fatima and Agonos, Mariam Jayne and Ruijgrok, Kris and
              Suarez, Gerard Martin",
  journal  = "Int. J. Commun.",
  volume   =  19,
  number   =  0,
  pages    =  21,
  abstract = "This study conceptualizes influence operations (IOs), an
              enterprise that orchestrates manipulative and inauthentic
              activities to achieve political advantage, as a contemporary form
              of brokerage during elections. It investigates the empirical case
              of IOs engaged in covert political campaigning in the 2022
              Philippine General Elections through qualitative field research.
              Drawing from 22 in-depth interviews with IO leads and staff, we
              define IOs’ broker attributes, their brokerage processes, and the
              capital and value they generate through brokerage. We identify
              four mechanisms of brokerage by IOs: infrastructural capacity,
              reputation manipulation, relationship building at scale, and
              obscured accountability. These mechanisms complement the brokerage
              work by aboveboard campaigns and other brokers by compensating for
              their limitations and innovating campaign strategies. We argue
              that IOs are not extraneous deviations but are logical extensions
              of existing political infrastructures and should be understood as
              operating with other normative forms of political campaigning.",
  month    =  mar,
  year     =  2025,
  language = "en"
}

@INCOLLECTION{Bastos2025-ya,
  title     = "So Long Twitter, and Thanks for All the Tweets",
  author    = "Bastos, M",
  editor    = "Bruns, A and Enli, G and Larsson, A O and Robinson, J Y and
               Bosch, T",
  publisher = "Routledge",
  address   = "London",
  abstract  = "This chapter reviews the historical contribution of Twitter
               before it was rebranded as X in July 2023. Twitter was an open
               platform for social sciences research, particularly political
               communication, a source of social data so prevalent in the early
               21st century that researchers referred to this scholarship as
               ‘Twitter studies.’ We revisit the many Application Programming
               Interfaces that Twitter offered to developers and researchers,
               including the REST, Search, Streaming, Academic, and Compliance
               APIs in addition to databases of political communication the
               company curated and shared with the research community before its
               contentious acquisition by Elon Musk in late 2022. The chapter
               concludes with an assessment of the research approaches developed
               for ‘Twitter research’ and the extent to which they are
               transferable to the ‘post-API era.’",
  month     =  apr,
  year      =  2025,
  language  = "en"
}

@MISC{UnknownUnknown-nv,
  title        = "Durably reducing conspiracy beliefs through dialogues with
                  {AI} | Science",
  howpublished = "\url{https://www.science.org/doi/10.1126/science.adq1814}",
  note         = "Accessed: 2024-12-17"
}
